{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capturing Sentimental Opinions on Presidential Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we'll aim to capture the opinions and sentiments of a sample of electoral voters. We'll do this by analyzing their tweets on a daily basis over a period of time to see how these opinions are varying or changing over time. \n",
    "\n",
    "Can analyzing sentiments of tweets from a sample during a given period provide insight to how an election will swing? The main goal of the project is to examine and analyze tweets containing reference to candidates vying for a presidential spot, classify these tweets into positive, negative or neutral sentiments and from these, try to conclude on how much online sentiments provide for a good indicator to predict the results of an election."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data Set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set we used in this project is the Sentiment140 dataset. You can find the data set [here](http://help.sentiment140.com/for-students). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data Set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we'll do a quick exploration of the data set to find irregularities and understand the composition of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What questions should we try to answer while looking at the data? (Please add ideas)\n",
    "1. How many positive/negative records do we have?\n",
    "2. Are there null/empty records?\n",
    "3. Do we really need all the columns? Which features are important?\n",
    "4. The text column, do we need @usernames, RTs, and any unnecessary text?\n",
    "5. Are we taking neutral records into consideration or just positives and negatives?\n",
    "6. Do we take into consideration tweets that contain e.g \"I wish\", \"I hope\" (without comparison these tweets might be deemed neutral, otherwise positive or negative).\n",
    "7. How do we plan to prepare data to prevent bias? (i.e Ratio of positive to negative tweets), to prevent the model from being biased towards the seniment with the higher ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>username</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811592</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mybirch</td>\n",
       "      <td>Need a hug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811594</td>\n",
       "      <td>Mon Apr 06 22:20:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>coZZ</td>\n",
       "      <td>@LOLTrish hey  long time no see! Yes.. Rains a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811795</td>\n",
       "      <td>Mon Apr 06 22:20:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>2Hood4Hollywood</td>\n",
       "      <td>@Tatiana_K nope they didn't have it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1467812025</td>\n",
       "      <td>Mon Apr 06 22:20:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mimismo</td>\n",
       "      <td>@twittera que me muera ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment          id                          date     query  \\\n",
       "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "5          0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "6          0  1467811592  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
       "7          0  1467811594  Mon Apr 06 22:20:03 PDT 2009  NO_QUERY   \n",
       "8          0  1467811795  Mon Apr 06 22:20:05 PDT 2009  NO_QUERY   \n",
       "9          0  1467812025  Mon Apr 06 22:20:09 PDT 2009  NO_QUERY   \n",
       "\n",
       "          username                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "5         joy_wolf                      @Kwesidei not the whole crew   \n",
       "6          mybirch                                        Need a hug   \n",
       "7             coZZ  @LOLTrish hey  long time no see! Yes.. Rains a...  \n",
       "8  2Hood4Hollywood               @Tatiana_K nope they didn't have it   \n",
       "9          mimismo                          @twittera que me muera ?   "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset = \"./dataset/training.1600000.processed.noemoticon.csv\"\n",
    "cols = ['sentiment', 'id', 'date', 'query', 'username', 'text']\n",
    "df = pd.read_csv(dataset, header=None, names=cols, encoding='latin-1')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.600000e+06</td>\n",
       "      <td>1.600000e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>1.998818e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.000001e+00</td>\n",
       "      <td>1.935761e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.467810e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.956916e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>2.002102e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>2.177059e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>2.329206e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentiment            id\n",
       "count  1.600000e+06  1.600000e+06\n",
       "mean   2.000000e+00  1.998818e+09\n",
       "std    2.000001e+00  1.935761e+08\n",
       "min    0.000000e+00  1.467810e+09\n",
       "25%    0.000000e+00  1.956916e+09\n",
       "50%    2.000000e+00  2.002102e+09\n",
       "75%    4.000000e+00  2.177059e+09\n",
       "max    4.000000e+00  2.329206e+09"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "There are 1.6 million records and 6 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1600000, step=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentiment', 'id', 'date', 'query', 'username', 'text'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "There are no null values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "id           0\n",
       "date         0\n",
       "query        0\n",
       "username     0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "The columns id, date, query and username will not be useful in the training of the data so we will get rid of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del df['username']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentiment', 'text'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Data Cleaning\n",
    "Cleaning up the text column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the text in the text column is beyond the character limit of twitter (140 as at the time of collection of the dataset). This means there are some unnecessary characters that have been introduced while creating/collecting the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>textlength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>Awwh babs... you look so sad underneith that s...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0</td>\n",
       "      <td>Tuesdayï¿½ll start with reflection ï¿½n then a...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0</td>\n",
       "      <td>Whinging. My client&amp;amp;boss don't understand ...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0</td>\n",
       "      <td>@TheLeagueSF Not Fun &amp;amp; Furious? The new ma...</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0</td>\n",
       "      <td>#3 woke up and was having an accident - &amp;quot;...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0</td>\n",
       "      <td>My bathtub drain is fired: it haz 1 job 2 do, ...</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0</td>\n",
       "      <td>pears &amp;amp; Brie, bottle of Cabernet, and &amp;quo...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0</td>\n",
       "      <td>Have an invite for &amp;quot;Healthy Dining&amp;quot; ...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>0</td>\n",
       "      <td>Damnit I was really digging this season of Rea...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>0</td>\n",
       "      <td>Why do I keep looking...I know that what I rea...</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiment                                               text  textlength\n",
       "213           0  Awwh babs... you look so sad underneith that s...         142\n",
       "226           0  Tuesdayï¿½ll start with reflection ï¿½n then a...         141\n",
       "279           0  Whinging. My client&amp;boss don't understand ...         145\n",
       "343           0  @TheLeagueSF Not Fun &amp; Furious? The new ma...         145\n",
       "400           0  #3 woke up and was having an accident - &quot;...         144\n",
       "464           0  My bathtub drain is fired: it haz 1 job 2 do, ...         146\n",
       "492           0  pears &amp; Brie, bottle of Cabernet, and &quo...         150\n",
       "747           0  Have an invite for &quot;Healthy Dining&quot; ...         141\n",
       "957           0  Damnit I was really digging this season of Rea...         141\n",
       "1064          0  Why do I keep looking...I know that what I rea...         141"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['textlength'] = [len(t) for t in df.text]\n",
    "df[df.textlength > 140].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAFpCAYAAACS4uOlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGLpJREFUeJzt3X9sndWd5/H3NzeJPUnpQMC0kGQ21Wx218XS0JE3g9RI\nS+iIEFQJRtquSMuUJVZDVLAyCihp4z9apHHEjx2qwdqtBcRTWFEX1JmhCJFl2cSlirT9YbqBhnoo\n2dIBTyDxLEkbHDk/nLN/5HFw4Dr2tX1zc8+8X9LVvffc89z7DbI/Ppz7POdESglJUr7m1LoASVJ1\nGfSSlDmDXpIyZ9BLUuYMeknKnEEvSZkz6CUpcwa9JGXOoJekzBn0kpS5ubUuAOCyyy5Ly5Ytq3UZ\nklRXXn755X9OKTVN1u+CCPply5bR399f6zIkqa5ExD9OpZ9TN5KUOYNekjJn0EtS5gx6ScqcQS9J\nmTPoJSlzBr0kZc6gl6TMGfSSlDmDXppAb28vLS0tlEolWlpa6O3trXVJ0rRcEEsgSBea3t5eOjo6\n2L59OytXrmT37t20tbUBsHbt2hpXJ1UmUkq1roHW1tbkWje6kLS0tNDV1cWqVavOtPX19dHe3s7e\nvXtrWJn0gYh4OaXUOmk/g176qFKpxMjICPPmzTvTduLECRobGxkdHa1hZdIHphr0ztFLZTQ3N3Pv\nvfeeNUd/77330tzcXOvSpIoZ9FIZq1at4v7772fdunUcOXKEdevWcf/99581lSPVC4NeKqOvr48t\nW7bQ09PDRRddRE9PD1u2bKGvr6/WpUkVc45eKsM5etUD5+ilGWhubmb37t1nte3evds5etUlg14q\no6Ojg7a2Nvr6+jhx4gR9fX20tbXR0dFR69KkinnBlFTG2EVR7e3tDAwM0NzcTGdnpxdLqS45Ry9J\ndco5ekkSYNBLE2pvb6exsZGIoLGxkfb29lqXJE2LQS+V0d7eTnd3N9u2bWN4eJht27bR3d1t2Ksu\nOUcvldHY2Mi2bdvYtGnTmbaHHnqIrVu3MjIyUsPKpA+4qJk0AxHB8PAwCxYsONN29OhRFi5cyIXw\nOyOBX8ZKM9LQ0EB3d/dZbd3d3TQ0NNSoImn6PI9eKuMrX/kKW7ZsAWDDhg10d3ezZcsWNmzYUOPK\npMpNGvQR0Qj8CGgo+n8/pfSNiPgO8B+A3xZd/3NKaU9EBPDXwI3A0aL959UoXqqWrq4uALZu3crd\nd99NQ0MDGzZsONMu1ZNJ5+iL4F6YUno/IuYBu4GNwAbguZTS9z/U/0agndNB/yfAX6eU/uRcn+Ec\nvSRVbtbm6NNp7xdP5xW3c/11uAl4ojjux8DFEXHFVIqWLiRuDq5cTOnL2IgoRcQe4CDwYkrpJ8VL\nnRHxakR8KyLGvqVaDLw97vDBok2qG2Obg3d1dTEyMkJXVxcdHR2GverSlII+pTSaUroaWAKsiIgW\n4OvAvwP+PbAI2FJ0j3Jv8eGGiFgfEf0R0T80NDSt4qVq6ezsZPv27axatYp58+axatUqtm/fTmdn\nZ61LkypW0emVKaXDwA+BG1JK7xTTM8eAvwFWFN0GgaXjDlsC7C/zXo+klFpTSq1NTU3TKl6qloGB\nAVauXHlW28qVKxkYGKhRRdL0TRr0EdEUERcXj38P+FPgH8bm3Ysva28G9haHPAt8OU67BvhtSumd\nqlQvVYkbjygnUxnRXwH0RcSrwM84PUf/HPBkRPwC+AVwGfCXRf/ngV8D+4BHga/OetVSlbnxiHIy\n6Xn0KaVXgc+Uab9ugv4JuHPmpUm148Yjyolr3UhSnXKtG0kSYNBLUvYMeknKnEEvSZkz6CUpcwa9\nJGXOoJekzBn0kpQ5g16SMmfQSxNw4xHlwqCXyujt7WXjxo0MDw+TUmJ4eJiNGzca9qpLBr1UxubN\nmymVSvT09HDs2DF6enoolUps3ry51qVJFTPopTIGBwd54oknztph6oknnmBwcLDWpUkVM+ilCeza\nteusOfpdu3bVuiRpWgx6qYxFixbx4IMPsm7dOo4cOcK6det48MEHWbRoUa1Lkypm0EtlLFiwgIsu\nuoiurq6z7hcsWFDr0qSKGfRSGfv37+fhhx9m4cKFACxcuJCHH36Y/fs/ss+9dMGbdCtB6V+i5uZm\nlixZwt69e8+09fX1uTm46pIjeqkMNwdXThzRS2W4Obhy4ohekjLniF4qo7e3lzvuuIORkRFOnTrF\nr371K+644w4AR/WqO47opTLuuusujh49yn333cfw8DD33XcfR48e5a677qp1aVLFHNFLZbz33ns8\n8MADbNq0CYBNmzYxOjrqWjeqS47opQm0tLSc87lULwx6qYy5c+dy6623nnV65a233srcuf5PsOqP\nQS+VsWHDBg4fPszatWtpaGhg7dq1HD58mA0bNtS6NKliDk+kMrq6ugB49NFHSSlx+PBhvvrVr55p\nl+pJpJRqXQOtra2pv7+/1mVIUl2JiJdTSq2T9XPqRpIyN2nQR0RjRPw0Il6JiNci4t6i/VMR8ZOI\neCMinoqI+UV7Q/F8X/H6sur+EyRJ5zKVEf0x4LqU0h8BVwM3RMQ1wP3At1JKy4FDQFvRvw04lFL6\n18C3in5S3ent7T1rhyk3Ble9mjTo02nvF0/nFbcEXAd8v2h/HLi5eHxT8Zzi9c9FRMxaxdJ50Nvb\ny8aNGxkeHialxPDwMBs3bjTsVZemNEcfEaWI2AMcBF4E/i9wOKV0sugyCCwuHi8G3gYoXv8tcOls\nFi1V2+bNmymVSvT09HDs2DF6enoolUpeGau6NKWgTymNppSuBpYAK4Byuy+Mnb5TbvT+kVN7ImJ9\nRPRHRP/Q0NBU65XOi8HBQVasWMGaNWuYP38+a9asYcWKFQwODta6NKliFZ11k1I6DPwQuAa4OCLG\nzsNfAoztsTYILAUoXv994L0y7/VISqk1pdTa1NQ0veqlKnruuefYtm0bw8PDbNu2jeeee67WJUnT\nMpWzbpoi4uLi8e8BfwoMAH3Afyy63Qb8oHj8bPGc4vVd6UI4WV+q0Pz58+nq6uJjH/sYXV1dzJ8/\nv9YlSdMylStjrwAej4gSp/8wPJ1Sei4ifgl8LyL+Evg/wPai/3bgv0fEPk6P5G+pQt1S1R07doyR\nkREigpGREY4dO1brkqRpmTToU0qvAp8p0/5rTs/Xf7h9BPjCrFQn1UhEcN111/Huu+9y8OBBLr30\nUq666ip27dpV69KkinllrFRGSomXXnqJdevWceTIEdatW8dLL72Es5CqRy5qJpVx1VVXsXz5crZu\n3crdd99NQ0MDn//853njjTdqXZpUMUf0UhkdHR288sor7Nixg+PHj7Njxw5eeeUVOjo6al2aVDFH\n9FIZYxuAt7e3MzAwQHNzM52dnW4MrrrkMsWSVKdcpliSBBj0kpQ9g16aQHt7O42NjUQEjY2NtLe3\n17okaVoMeqmM9vZ2uru7z1rrpru727BXXfLLWKmMxsZGtm3bxqZNm860PfTQQ2zdupWRkZEaViZ9\nwC9jpRk4duwYr7/++llTN6+//rrr3aguGfRSGXPmzOGxxx47a+rmscceY84cf2VUf/yplcqYaPdL\nd8VUPTLopTJGR0e59tprueeee1i4cCH33HMP1157LaOjo7UuTaqYQS+VMXfuXPbs2cPOnTs5fvw4\nO3fuZM+ePcyd66ohqj/+1EplfPzjH+fQoUOsXbuWgwcPcvnll3Po0CEuueSSWpcmVcwRvVTGoUOH\naGho4MCBA6SUOHDgAA0NDRw6dKjWpUkVM+ilMkqlEgsWLGDXrl0cP36cXbt2sWDBAkqlUq1Lkypm\n0EtlnDx5knnz5p3VNm/ePE6ePFmjiqTpM+ilCdx+++1n1rtpb2/n9ttvr3VJ0rT4ZaxUxpIlS3j8\n8cd58sknWblyJbt37+ZLX/oSS5YsqXVpUsUc0UtlPPDAA7z//vusXr2a+fPns3r1at5//30eeOCB\nWpcmVcyglybQ2NjI4sWLmTNnDosXL6axsbHWJUnTYtBLZXR2dvLUU0/x5ptvMjo6yptvvslTTz1F\nZ2dnrUuTKuYyxVIZpVKJkZGRs868OXHiBI2NjS6DoAuGyxRLM9Dc3Mzu3bvPatu9ezfNzc01qkia\nPoNeKqOjo4O2tjb6+vo4ceIEfX19tLW10dHRUevSpIp5eqVUxtq1a4HTWwoODAzQ3NxMZ2fnmXap\nnjiil6TMOaKXyujt7aWjo4Pt27efuWCqra0NwFG96o5n3UhltLS00NXVxapVq8609fX10d7ezt69\ne2tYmfSBWTvrJiKWRkRfRAxExGsRsbFo/2ZE/FNE7CluN4475usRsS8iXo+I1TP7p0jn38DAAIOD\ng7S0tFAqlWhpaWFwcJCBgYFalyZVbCpTNyeBu1NKP4+Ii4CXI+LF4rVvpZT+y/jOEfFp4BbgKuBK\n4H9FxL9JKXnyserGlVdeyebNm/nud797Zurmi1/8IldeeWWtS5MqNumIPqX0Tkrp58XjI8AAsPgc\nh9wEfC+ldCyl9CawD1gxG8VK59OHNwJ3Y3DVq4rOuomIZcBngJ8UTXdFxKsR0RMRY3usLQbeHnfY\nIOf+wyBdcPbv38/NN9/MmjVrmD9/PmvWrOHmm29m//79tS5NqtiUgz4iPgb8LfAXKaXfAd8G/hC4\nGngH+KuxrmUO/8g3vhGxPiL6I6J/aGio4sKlarryyit55pln2LFjB8ePH2fHjh0888wzTt2oLk3p\n9MqImMfpkH8ypfR3ACmlA+NefxR4rng6CCwdd/gS4CPDoJTSI8AjcPqsm+kUL1XT4cOHWb16NSdO\nnGDevHnMnTuXSy+9tNZlSRWbylk3AWwHBlJKD41rv2Jctz8Dxs45exa4JSIaIuJTwHLgp7NXslR9\ng4ODjIyMcOrUKQBOnTrFyMgIg4ODNa5MqtxURvSfBf4c+EVE7CnatgJrI+JqTk/L/Aa4AyCl9FpE\nPA38ktNn7NzpGTeqRw0NDXzyk5/krbfeYunSpbz77ruMjIzUuiypYl4wJZUxdoZNqVRidHT0zD3A\nhfA7I4HLFEuzYizcXYNe9cygl6TMGfTSOcyZM+ese6ke+dMrTSAiKJVKwOm5eq+MVb1ymWJpAikl\nTpw4AXDmXqpHjuglKXMGvSRlzqCXpMwZ9JKUOYNekjJn0EtS5gx66Ry8YEo58KdXOofxyxRL9cqg\nl6TMGfSSlDmDXpIyZ9BLUuYMeknKnEEvSZkz6KVzGFuD3rXoVc8MeukcxjYCd0Nw1TODXpIyZ9BL\nUuYMeknKnEEvSZkz6CUpcwa9JGXOoJekzBn0kpQ5g16SMmfQS1LmDHpJytykQR8RSyOiLyIGIuK1\niNhYtC+KiBcj4o3i/pKiPSLi4YjYFxGvRsQfV/sfIUma2FRG9CeBu1NKzcA1wJ0R8Wnga8DOlNJy\nYGfxHGANsLy4rQe+PetVS5KmbNKgTym9k1L6efH4CDAALAZuAh4vuj0O3Fw8vgl4Ip32Y+DiiLhi\n1iuXJE1JRXP0EbEM+AzwE+ATKaV34PQfA+Dyotti4O1xhw0WbZKkGphy0EfEx4C/Bf4ipfS7c3Ut\n0/aRxbwjYn1E9EdE/9DQ0FTLkCRVaEpBHxHzOB3yT6aU/q5oPjA2JVPcHyzaB4Gl4w5fAuz/8Hum\nlB5JKbWmlFqbmpqmW78kaRJTOesmgO3AQErpoXEvPQvcVjy+DfjBuPYvF2ffXAP8dmyKR5J0/s2d\nQp/PAn8O/CIi9hRtW4H7gKcjog14C/hC8drzwI3APuAocPusVixJqsikQZ9S2k35eXeAz5Xpn4A7\nZ1iXVBWzscn3VN7DPWZ1IZnKiF7KxlQD+Fxhboir3rgEglTG9ddfX1G7dCEz6KUyXnjhBa6//voz\nI/uI4Prrr+eFF16ocWVS5Zy6kSYwFuoRwalTp2pcjTR9juglKXMGvSRlzqCXpMwZ9JKUOYNekjJn\n0EtS5gx6ScqcQS9JmTPoJSlzBr0kZc6gl6TMGfSSlDmDXpIyZ9BLUuYMeknKnEEvSZkz6CUpcwa9\nJGXOoJekzBn0kpQ5g16SMmfQS1LmDHpJypxBL0mZM+glKXMGvSRlzqCXpMxNGvQR0RMRByNi77i2\nb0bEP0XEnuJ247jXvh4R+yLi9YhYXa3CJUlTM5UR/XeAG8q0fyuldHVxex4gIj4N3AJcVRzz3yKi\nNFvFSpIqN2nQp5R+BLw3xfe7CfheSulYSulNYB+wYgb1SZJmaCZz9HdFxKvF1M4lRdti4O1xfQaL\nNklSjUw36L8N/CFwNfAO8FdFe5Tpm8q9QUSsj4j+iOgfGhqaZhmSpMlMK+hTSgdSSqMppVPAo3ww\nPTMILB3XdQmwf4L3eCSl1JpSam1qappOGZKkKZhW0EfEFeOe/hkwdkbOs8AtEdEQEZ8ClgM/nVmJ\nkqSZmDtZh4joBa4FLouIQeAbwLURcTWnp2V+A9wBkFJ6LSKeBn4JnATuTCmNVqd0SdJUREplp9DP\nq9bW1tTf31/rMqSyIoIL4fdE+rCIeDml1DpZP6+MlaTMGfSSlDmDXpIyZ9BLUuYMeknKnEEvSZkz\n6CUpcwa9JGXOoJekzBn0kpQ5g16SMmfQS1LmDHpJypxBL0mZM+glKXMGvSRlzqCXpMwZ9JKUOYNe\nkjJn0EtS5gx6ScqcQS9JmTPoJSlzBr0kZc6gl6TMGfSSlDmDXpIyZ9BLUuYMeknKnEEvSZkz6CUp\nc5MGfUT0RMTBiNg7rm1RRLwYEW8U95cU7RERD0fEvoh4NSL+uJrFS5ImN5UR/XeAGz7U9jVgZ0pp\nObCzeA6wBlhe3NYD356dMqWPWrRoERFR9RtQ9c9YtGhRjf9rKmdzJ+uQUvpRRCz7UPNNwLXF48eB\nHwJbivYnUkoJ+HFEXBwRV6SU3pmtgqUxhw4d4vSPWv0b+4MiVcN05+g/MRbexf3lRfti4O1x/QaL\nNklSjcz2l7HlhiVlh1wRsT4i+iOif2hoaJbLkCSNmW7QH4iIKwCK+4NF+yCwdFy/JcD+cm+QUnok\npdSaUmptamqaZhmSpMlMN+ifBW4rHt8G/GBc+5eLs2+uAX7r/Lwk1dakX8ZGRC+nv3i9LCIGgW8A\n9wFPR0Qb8BbwhaL788CNwD7gKHB7FWqWJFVgKmfdrJ3gpc+V6ZuAO2dalCRp9nhlrCRlzqCXpMwZ\n9JKUOYNekjJn0EtS5gx6ScqcQS9JmTPoJSlzBr0kZc6gl6TMGfSSlDmDXpIyZ9BLUuYMeknKnEEv\nSZkz6CUpcwa9JGXOoJekzBn0kpQ5g16SMjfp5uDShSp94+Pwzd+vdRmzIn3j47UuQRkz6FW34t7f\nkVKqdRmzIiJI36x1FcqVUzeSlDmDXpIyZ9BLUuYMeknKnEEvSZkz6CUpcwa9JGXOoJekzBn0kpQ5\ng16SMjejJRAi4jfAEWAUOJlSao2IRcBTwDLgN8B/SikdmlmZkqTpmo0R/aqU0tUppdbi+deAnSml\n5cDO4rkkqUaqMXVzE/B48fhx4OYqfIYkaYpmGvQJ+J8R8XJErC/aPpFSegeguL98hp8hSZqBmS5T\n/NmU0v6IuBx4MSL+YaoHFn8Y1gP8wR/8wQzLkCRNZEYj+pTS/uL+IPD3wArgQERcAVDcH5zg2EdS\nSq0ppdampqaZlCFJOodpB31ELIyIi8YeA9cDe4FngduKbrcBP5hpkZKk6ZvJ1M0ngL+PiLH3+W5K\n6X9ExM+ApyOiDXgL+MLMy5QkTde0gz6l9Gvgj8q0/z/gczMpSpqqYqBR9y655JJal6CMuWes6tb5\n2i82IrLZm1b/MrkEgiRlzqCXpMwZ9JKUOYNekjJn0EtS5gx6ScqcQS9JmTPoJSlzBr0kZc6gl6TM\nGfSSlDmDXpIyZ9BLUuYMeknKnEEvSZkz6CUpcwa9JGXOoJekzBn0kpQ5g16SMmfQS1LmDHpJypxB\nL0mZM+glKXMGvSRlzqCXpMwZ9JKUOYNekjJn0EtS5ubWugDpfIqI83JcSmlanyNVQ9VG9BFxQ0S8\nHhH7IuJr1focqRIppfNyky4kVQn6iCgB/xVYA3waWBsRn67GZ0mSzq1aI/oVwL6U0q9TSseB7wE3\nVemzJEnnUK2gXwy8Pe75YNEmSTrPqhX05b65OmviMiLWR0R/RPQPDQ1VqQxJUrWCfhBYOu75EmD/\n+A4ppUdSSq0ppdampqYqlSFJqlbQ/wxYHhGfioj5wC3As1X6LEnSOVTlPPqU0smIuAt4ASgBPSml\n16rxWZKkc6vaBVMppeeB56v1/pKkqXEJBEnKnEEvSZkz6CUpcwa9JGXOoJekzMWFsNJeRAwB/1jr\nOqQJXAb8c62LkMr4VymlSa84vSCCXrqQRUR/Sqm11nVI0+XUjSRlzqCXpMwZ9NLkHql1AdJMOEcv\nSZlzRC9JmTPopQlERE9EHIyIvbWuRZoJg16a2HeAG2pdhDRTBr00gZTSj4D3al2HNFMGvSRlzqCX\npMwZ9JKUOYNekjJn0EsTiIhe4H8D/zYiBiOirdY1SdPhlbGSlDlH9JKUOYNekjJn0EtS5gx6Scqc\nQS9JmTPoJSlzBr0kZc6gl6TM/X9mlJWfFF1+ygAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2d180033278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "plt.boxplot(df.textlength)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just defining a dictionary to define the dataset we now have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_shape': (1600000, 3),\n",
      " 'sentiment': {'description': 'sentiment class - 0:negative, 1:positive',\n",
      "               'type': dtype('int64')},\n",
      " 'text': {'description': 'tweet text', 'type': dtype('O')},\n",
      " 'textlength': {'description': 'Length of the tweet before cleaning',\n",
      "                'type': dtype('int64')}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "data_dict = {\n",
    "    'sentiment':{\n",
    "        'type':df.sentiment.dtype,\n",
    "        'description':'sentiment class - 0:negative, 1:positive'\n",
    "    },\n",
    "    'text':{\n",
    "        'type':df.text.dtype,\n",
    "        'description':'tweet text'\n",
    "    },\n",
    "    'textlength':{\n",
    "        'type':df.textlength.dtype,\n",
    "        'description':'Length of the tweet before cleaning'\n",
    "    },\n",
    "    'dataset_shape':df.shape\n",
    "}\n",
    "\n",
    "pprint(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HTML Decoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pears &amp; Brie, bottle of Cabernet, and &quot;Win a Date With Tad Hamilton&quot;... oh gawwd my life flashed forward to when I'm 40 with my 75 cats \""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[492]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pears & Brie, bottle of Cabernet, and \"Win a Date With Tad Hamilton\"... oh gawwd my life flashed forward to when I'm 40 with my 75 cats \n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "example1 = BeautifulSoup(df.text[492], 'lxml')\n",
    "print (example1.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing @ Mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@TheLeagueSF Not Fun &amp; Furious? The new mantra for the Bay 2 Breakers? It was getting 2 rambunctious;the city overreacted &amp; clamped down '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[343]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Not Fun &amp; Furious? The new mantra for the Bay 2 Breakers? It was getting 2 rambunctious;the city overreacted &amp; clamped down '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.sub(r'@[A-Za-z0-9]+','',df.text[343])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing URL Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@switchfoot  - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('https?://[A-Za-z0-9./]+','',df.text[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UTF8-Byte Order Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tuesdayï¿½ll start with reflection ï¿½n then a lecture in Stress reducing techniques. That sure might become very useful for us accompaniers '"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[226]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tuesday`ll start with reflection `n then a lecture in Stress reducing techniques. That sure might become very useful for us accompaniers '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[226].replace(u\"ï¿½\", \"`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashtag/Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"@machineplay I'm so sorry you're having to go through this. Again.  #therapyfail\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" machineplay I'm so sorry you're having to go through this  Again    therapyfail\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(\"[^a-zA-Z']\", \" \", df.text[175])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awww that bummer you shoulda got david carr of third day to do it',\n",
       " 'is upset that he can not update his facebook by texting it and might cry as result school today also blah',\n",
       " 'dived many times for the ball managed to save the rest go out of bounds',\n",
       " 'my whole body feels itchy and like its on fire',\n",
       " 'no it not behaving at all mad why am here because can not see you all over there',\n",
       " 'not the whole crew',\n",
       " 'need hug',\n",
       " 'hey long time no see yes rains bit only bit lol fine thanks how you',\n",
       " 'nope they did not have it',\n",
       " 'que me muera',\n",
       " 'spring break in plain city it snowing',\n",
       " 'just re pierced my ears',\n",
       " 'could not bear to watch it and thought the ua loss was embarrassing',\n",
       " 'it it counts idk why did either you never talk to me anymore',\n",
       " 'would ve been the first but did not have gun not really though zac snyder just doucheclown',\n",
       " 'wish got to watch it with you miss you and how was the premiere',\n",
       " 'hollis death scene will hurt me severely to watch on film wry is directors cut not out now',\n",
       " 'about to file taxes',\n",
       " 'ahh ive always wanted to see rent love the soundtrack',\n",
       " 'oh dear were you drinking out of the forgotten table drinks',\n",
       " 'was out most of the day so did not get much done',\n",
       " 'one of my friend called me and asked to meet with her at mid valley today but ve no time sigh',\n",
       " 'baked you cake but ated it',\n",
       " 'this week is not going as had hoped',\n",
       " 'blagh class at tomorrow',\n",
       " 'hate when have to call and wake people up',\n",
       " 'just going to cry myself to sleep after watching marley and me',\n",
       " 'im sad now miss lilly',\n",
       " 'ooooh lol that leslie and ok will not do it again so leslie will not get mad again',\n",
       " 'meh almost lover is the exception this track gets me depressed every time',\n",
       " 'some hacked my account on aim now have to make new one',\n",
       " 'want to go to promote gear and groove but unfornately no ride there may going to the one in anaheim in may though',\n",
       " 'thought sleeping in was an option tomorrow but realizing that it now is not evaluations in the morning and work in the afternoon',\n",
       " 'awe love you too am here miss you',\n",
       " 'cry my asian eyes to sleep at night',\n",
       " 'ok sick and spent an hour sitting in the shower cause was too sick to stand and held back the puke like champ bed now',\n",
       " 'ill tell ya the story later not good day and ill be workin for like three more hours',\n",
       " 'sorry bed time came here gmt',\n",
       " 'do not either its depressing do not think even want to know about the kids in suitcases',\n",
       " 'bed class work gym or then class another day that gonna fly by miss my girlfriend',\n",
       " 'really do not feel like getting up today but got to study to for tomorrows practical exam',\n",
       " 'he the reason for the teardrops on my guitar the only one who has enough of me to break my heart',\n",
       " 'sad sad sad do not know why but hate this feeling wanna sleep and still can not',\n",
       " 'soo wish was there to see you finally comfortable im sad that missed it',\n",
       " 'falling asleep just heard about that tracy girl body being found how sad my heart breaks for that family',\n",
       " 'yay happy for you with your job but that also means less time for me and you',\n",
       " 'just checked my user timeline on my blackberry it looks like the twanking is still happening are ppl still having probs bgs and uids',\n",
       " 'oh man was ironing fave top to wear to meeting burnt it',\n",
       " 'is strangely sad about lilo and samro breaking up',\n",
       " 'oh so sorry did not think about that before retweeting',\n",
       " 'broadband plan massive broken promise via still waiting for broadband we are',\n",
       " 'wow tons of replies from you may have to unfollow so can see my friends tweets you re scrolling the feed lot',\n",
       " 'our duck and chicken are taking wayyy too long to hatch',\n",
       " 'put vacation photos online few yrs ago pc crashed and now forget the name of the site',\n",
       " 'need hug',\n",
       " 'not sure what they are only that they are pos as much as want to dont think can trade away company assets sorry andy',\n",
       " 'hate when that happens',\n",
       " 'have sad feeling that dallas is not going to show up gotta say though you think more shows would use music from the game mmm',\n",
       " 'ugh degrees tomorrow',\n",
       " 'where did move to thought were already in sd hmmm random found me glad to hear yer doing well',\n",
       " 'miss my ps it out of commission wutcha playing have you copped blood on the sand',\n",
       " 'just leaving the parking lot of work',\n",
       " 'the life is cool but not for me',\n",
       " 'sadly though ve never gotten to experience the post coitus cigarette before and now never will',\n",
       " 'had such nice day too bad the rain comes in tomorrow at am',\n",
       " 'too bad will not be around lost my job and can not even pay my phone bill lmao aw shucks',\n",
       " 'damm back to school tomorrow',\n",
       " 'mo jobs no money how in the hell is min wage here clams an hour',\n",
       " 'not forever see you soon',\n",
       " 'agreed saw the failwhale allllll day today',\n",
       " 'oh haha dude dont really look at em unless someone says hey added you sorry so terrible at that need pop up',\n",
       " 'sure you re right need to start working out with you and the nikster or jared at least',\n",
       " 'really hate how people diss my bands trace is clearly not ugly',\n",
       " 'gym attire today was puma singlet adidas shorts and black business socks and leather shoes lucky did not run into any cute girls',\n",
       " 'why will not you show my location',\n",
       " 'no picnic my phone smells like citrus',\n",
       " 'my donkey is sensitive about such comments nevertheless he and me be glad to see your mug asap charger is still awol',\n",
       " 'no new csi tonight fml',\n",
       " 'think my arms are sore from tennis',\n",
       " 'wonders why someone that like so much can make you so unhappy in split seccond depressed',\n",
       " 'sleep soon just hate saying bye and see you tomorrow for the night',\n",
       " 'just got ur newsletter those fares really are unbelievable shame already booked and paid for mine',\n",
       " 'missin the boo',\n",
       " 'me too itm',\n",
       " 'damn do not have any chalk my chalkboard is useless',\n",
       " 'had blast at the getty villa but hates that she had sore throat all day it just getting worse too',\n",
       " 'hey missed ya at the meeting sup mama',\n",
       " 'my tummy hurts wonder if the hypnosis has anything to do with it if so it working get it stop smoking',\n",
       " 'why is it always the fat ones',\n",
       " 'sorry babe my fam annoys me too thankfully they re asleep right now muahaha evil laugh',\n",
       " 'should have paid more attention when we covered photoshop in my webpage design class in undergrad',\n",
       " 'wednesday my day do not know what do',\n",
       " 'poor cameron the hills',\n",
       " 'pray for me please the ex is threatening to start sh at my our babies st birthday party what jerk and still have headache',\n",
       " 'hmm do really enjoy being with him if the problems are too constants should think things more find someone ulike',\n",
       " 'strider is sick little puppy',\n",
       " 'so rylee grace wana go steve party or not sadly since its easter wnt able do much but ohh well',\n",
       " 'hey actually won one of my bracket pools too bad it was not the one for money',\n",
       " 'you do not follow me either and work for you',\n",
       " 'bad nite for the favorite teams astros and spartans lose the nite out with was good']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+'\n",
    "pat2 = r'https?://[^ ]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "www_pat = r'www.[^ ]+'\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def tweet_cleaner_updated(text):\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped = re.sub(combined_pat, '', bom_removed)\n",
    "    stripped = re.sub(www_pat, '', stripped)\n",
    "    lower_case = stripped.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], lower_case)\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", neg_handled)\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()\n",
    "testing = df.text[:100]\n",
    "\n",
    "test_result = []\n",
    "for t in testing:\n",
    "    test_result.append(tweet_cleaner_updated(t))\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the tweets...\n",
      "\n",
      "Tweets 100000 of 1600000 has been processed\n",
      "Tweets 200000 of 1600000 has been processed\n",
      "Tweets 300000 of 1600000 has been processed\n",
      "Tweets 400000 of 1600000 has been processed\n",
      "Tweets 500000 of 1600000 has been processed\n",
      "Tweets 600000 of 1600000 has been processed\n",
      "Tweets 700000 of 1600000 has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b' i just received my G8 viola exam.. and its... well... .. disappointing.. :\\\\..'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets 800000 of 1600000 has been processed\n",
      "Tweets 900000 of 1600000 has been processed\n",
      "Tweets 1000000 of 1600000 has been processed\n",
      "Tweets 1100000 of 1600000 has been processed\n",
      "Tweets 1200000 of 1600000 has been processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\bs4\\__init__.py:219: UserWarning: \"b'E3 ON PLAYSTATION HOME IN ABOUT AN HOUR!!!!!!!!!! \\\\../  \\\\../'\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  ' Beautiful Soup.' % markup)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets 1300000 of 1600000 has been processed\n",
      "Tweets 1400000 of 1600000 has been processed\n",
      "Tweets 1500000 of 1600000 has been processed\n",
      "Tweets 1600000 of 1600000 has been processed\n"
     ]
    }
   ],
   "source": [
    "lengthofrecords = 1600000\n",
    "print (\"Cleaning and parsing the tweets...\\n\")\n",
    "clean_tweet_texts = []\n",
    "for i in range(0,lengthofrecords):\n",
    "    if( (i+1)%100000 == 0 ):\n",
    "        print (\"Tweets %d of %d has been processed\" % ( i+1, lengthofrecords ))                                                                    \n",
    "    clean_tweet_texts.append(tweet_cleaner_updated(df['text'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['awww that bummer you shoulda got david carr of third day to do it',\n",
       " 'is upset that he can not update his facebook by texting it and might cry as result school today also blah',\n",
       " 'dived many times for the ball managed to save the rest go out of bounds',\n",
       " 'my whole body feels itchy and like its on fire',\n",
       " 'no it not behaving at all mad why am here because can not see you all over there',\n",
       " 'not the whole crew',\n",
       " 'need hug',\n",
       " 'hey long time no see yes rains bit only bit lol fine thanks how you',\n",
       " 'nope they did not have it',\n",
       " 'que me muera']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytweets = []\n",
    "for sentence in clean_tweet_texts:\n",
    "    newsentence = re.sub(\"\\s'\\s\", \"'\", sentence)\n",
    "    mytweets.append(newsentence)\n",
    "mytweets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>awww that bummer you shoulda got david carr of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can not update his facebook b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dived many times for the ball managed to save ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no it not behaving at all mad why am here beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  awww that bummer you shoulda got david carr of...       0\n",
       "1  is upset that he can not update his facebook b...       0\n",
       "2  dived many times for the ball managed to save ...       0\n",
       "3     my whole body feels itchy and like its on fire       0\n",
       "4  no it not behaving at all mad why am here beca...       0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.DataFrame(mytweets,columns=['text'])\n",
    "clean_df['target'] = df.sentiment\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_df.to_csv('clean_tweet.csv', index=False, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv = 'clean_tweet.csv'\n",
    "my_df = pd.read_csv(csv)\n",
    "my_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      "text      1596041 non-null object\n",
      "target    1600000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "my_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text       True\n",
       "target    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_df.isnull().any(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 and 7:\n",
    "The dataset we will use for the training doesn't have neutral sentiments, only (0 - negative and 4 - positive) So we will just work with positives and negatives. Since the dataset is balanced between the two classes (800,000), bias shouldn't be a problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    800000\n",
       "0    800000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6:\n",
    "True without further context, tweets with those terms will be deemde neutral but the model has to take the whole context of the sentence/tweet into consideration before classifying into positive or negative.\n",
    "E.g. I hope Buhari doesn't become president again = Negative\n",
    "     I wish I had been more accepting of Atiku = Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
